{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data paths\n",
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data generator for real-time data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,  # Increase rotation range\n",
    "    width_shift_range=0.3,  # Increase shift range\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,  # Increase shear range\n",
    "    zoom_range=0.3,  # Increase zoom range\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # Add vertical flip\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1211 images belonging to 4 classes.\n",
      "Found 99 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create generators for training and test datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Resize images to a common size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Since it's a multiclass classification\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hirun\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Generate the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.6),  # Dropout for regularization\n",
    "    layers.Dense(len(train_generator.class_indices), activation='softmax')  # Output layer for multiclass\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\hirun\\appdata\\roaming\\python\\python312\\site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hirun\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3631 - loss: 1.3914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hirun\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.3643 - loss: 1.3885 - val_accuracy: 0.4896 - val_loss: 1.3389\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.9872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hirun\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6562 - loss: 0.9872 - val_accuracy: 0.4792 - val_loss: 1.3739\n",
      "Epoch 3/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 734ms/step - accuracy: 0.4916 - loss: 1.1316 - val_accuracy: 0.5104 - val_loss: 1.2885\n",
      "Epoch 4/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4375 - loss: 1.1986 - val_accuracy: 0.5208 - val_loss: 1.2874\n",
      "Epoch 5/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 620ms/step - accuracy: 0.5487 - loss: 1.1058 - val_accuracy: 0.5208 - val_loss: 1.2810\n",
      "Epoch 6/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5312 - loss: 1.1530 - val_accuracy: 0.5000 - val_loss: 1.3734\n",
      "Epoch 7/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 847ms/step - accuracy: 0.5754 - loss: 1.0918 - val_accuracy: 0.5521 - val_loss: 1.2880\n",
      "Epoch 8/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.5625 - loss: 0.9685 - val_accuracy: 0.5312 - val_loss: 1.5296\n",
      "Epoch 9/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 786ms/step - accuracy: 0.5537 - loss: 1.0793 - val_accuracy: 0.6042 - val_loss: 1.1007\n",
      "Epoch 10/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5938 - loss: 1.1626 - val_accuracy: 0.6042 - val_loss: 1.0843\n",
      "Epoch 11/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.5911 - loss: 1.0205 - val_accuracy: 0.5521 - val_loss: 1.3480\n",
      "Epoch 12/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5185 - loss: 1.0894 - val_accuracy: 0.5417 - val_loss: 1.2866\n",
      "Epoch 13/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 907ms/step - accuracy: 0.5778 - loss: 1.0493 - val_accuracy: 0.5312 - val_loss: 1.2750\n",
      "Epoch 14/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5938 - loss: 1.2285 - val_accuracy: 0.5417 - val_loss: 1.2304\n",
      "Epoch 15/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 705ms/step - accuracy: 0.5740 - loss: 1.0260 - val_accuracy: 0.5521 - val_loss: 1.0935\n",
      "Epoch 16/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 1.0744 - val_accuracy: 0.5521 - val_loss: 1.0562\n",
      "Epoch 17/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 522ms/step - accuracy: 0.5703 - loss: 1.0289 - val_accuracy: 0.5833 - val_loss: 1.3548\n",
      "Epoch 18/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5312 - loss: 1.6354 - val_accuracy: 0.5938 - val_loss: 1.1181\n",
      "Epoch 19/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 506ms/step - accuracy: 0.6206 - loss: 0.9303 - val_accuracy: 0.5938 - val_loss: 1.0218\n",
      "Epoch 20/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5938 - loss: 0.9530 - val_accuracy: 0.5833 - val_loss: 1.0349\n",
      "Epoch 21/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 491ms/step - accuracy: 0.6100 - loss: 0.9436 - val_accuracy: 0.5833 - val_loss: 1.0296\n",
      "Epoch 22/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7500 - loss: 0.9241 - val_accuracy: 0.5625 - val_loss: 1.0531\n",
      "Epoch 23/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 481ms/step - accuracy: 0.6096 - loss: 0.9330 - val_accuracy: 0.5000 - val_loss: 1.0577\n",
      "Epoch 24/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 1.0802 - val_accuracy: 0.5521 - val_loss: 1.0094\n",
      "Epoch 25/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 490ms/step - accuracy: 0.6102 - loss: 0.9502 - val_accuracy: 0.5938 - val_loss: 0.9877\n",
      "Epoch 26/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5556 - loss: 1.0910 - val_accuracy: 0.6250 - val_loss: 1.0106\n",
      "Epoch 27/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 495ms/step - accuracy: 0.6290 - loss: 0.9045 - val_accuracy: 0.5833 - val_loss: 1.0594\n",
      "Epoch 28/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6875 - loss: 0.8011 - val_accuracy: 0.5938 - val_loss: 1.1467\n",
      "Epoch 29/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 522ms/step - accuracy: 0.6379 - loss: 0.8694 - val_accuracy: 0.6562 - val_loss: 0.9259\n",
      "Epoch 30/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.7412 - val_accuracy: 0.6458 - val_loss: 0.9291\n",
      "Epoch 31/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 489ms/step - accuracy: 0.6752 - loss: 0.8857 - val_accuracy: 0.6042 - val_loss: 0.9075\n",
      "Epoch 32/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5312 - loss: 1.2125 - val_accuracy: 0.6354 - val_loss: 0.9438\n",
      "Epoch 33/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 501ms/step - accuracy: 0.6638 - loss: 0.8828 - val_accuracy: 0.6354 - val_loss: 1.0268\n",
      "Epoch 34/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7500 - loss: 0.5867 - val_accuracy: 0.6458 - val_loss: 0.9797\n",
      "Epoch 35/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 539ms/step - accuracy: 0.6695 - loss: 0.8237 - val_accuracy: 0.6875 - val_loss: 0.8889\n",
      "Epoch 36/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7188 - loss: 1.1473 - val_accuracy: 0.7396 - val_loss: 0.8169\n",
      "Epoch 37/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.6764 - loss: 0.8280 - val_accuracy: 0.7396 - val_loss: 0.8699\n",
      "Epoch 38/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7500 - loss: 0.6071 - val_accuracy: 0.7292 - val_loss: 0.8709\n",
      "Epoch 39/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 492ms/step - accuracy: 0.7020 - loss: 0.7649 - val_accuracy: 0.6562 - val_loss: 0.8223\n",
      "Epoch 40/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7188 - loss: 0.6909 - val_accuracy: 0.6875 - val_loss: 0.7928\n",
      "Epoch 41/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.7056 - loss: 0.7516 - val_accuracy: 0.7083 - val_loss: 0.8181\n",
      "Epoch 42/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 0.7982 - val_accuracy: 0.6979 - val_loss: 0.8111\n",
      "Epoch 43/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 472ms/step - accuracy: 0.6943 - loss: 0.7882 - val_accuracy: 0.6875 - val_loss: 0.8241\n",
      "Epoch 44/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7188 - loss: 0.7545 - val_accuracy: 0.6979 - val_loss: 0.8471\n",
      "Epoch 45/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 604ms/step - accuracy: 0.6825 - loss: 0.8181 - val_accuracy: 0.6667 - val_loss: 0.9388\n",
      "Epoch 46/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6875 - loss: 0.6382 - val_accuracy: 0.6667 - val_loss: 0.9376\n",
      "Epoch 47/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 16s/step - accuracy: 0.7012 - loss: 0.7465 - val_accuracy: 0.7083 - val_loss: 0.8333\n",
      "Epoch 48/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7812 - loss: 0.6908 - val_accuracy: 0.7188 - val_loss: 0.8129\n",
      "Epoch 49/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 17s/step - accuracy: 0.7135 - loss: 0.7571 - val_accuracy: 0.6771 - val_loss: 0.8301\n",
      "Epoch 50/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7188 - loss: 0.6708 - val_accuracy: 0.7083 - val_loss: 0.8219\n",
      "Epoch 51/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 391ms/step - accuracy: 0.6632 - loss: 0.8291 - val_accuracy: 0.6562 - val_loss: 0.9571\n",
      "Epoch 52/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.8708 - val_accuracy: 0.6771 - val_loss: 0.8591\n",
      "Epoch 53/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 352ms/step - accuracy: 0.7046 - loss: 0.7424 - val_accuracy: 0.7083 - val_loss: 0.8122\n",
      "Epoch 54/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8125 - loss: 0.7290 - val_accuracy: 0.6979 - val_loss: 0.8201\n",
      "Epoch 55/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 360ms/step - accuracy: 0.7335 - loss: 0.6889 - val_accuracy: 0.7188 - val_loss: 0.8437\n",
      "Epoch 56/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6875 - loss: 0.6534 - val_accuracy: 0.7396 - val_loss: 0.8174\n",
      "Epoch 57/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 427ms/step - accuracy: 0.7134 - loss: 0.7007 - val_accuracy: 0.7188 - val_loss: 0.7629\n",
      "Epoch 58/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6875 - loss: 0.9246 - val_accuracy: 0.7083 - val_loss: 0.7479\n",
      "Epoch 59/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 418ms/step - accuracy: 0.7335 - loss: 0.6983 - val_accuracy: 0.7083 - val_loss: 0.7613\n",
      "Epoch 60/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7188 - loss: 0.6957 - val_accuracy: 0.7188 - val_loss: 0.7850\n",
      "Epoch 61/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 454ms/step - accuracy: 0.7372 - loss: 0.6877 - val_accuracy: 0.6146 - val_loss: 0.9579\n",
      "Epoch 62/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5938 - loss: 0.9580 - val_accuracy: 0.6250 - val_loss: 0.9591\n",
      "Epoch 63/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 511ms/step - accuracy: 0.7263 - loss: 0.7028 - val_accuracy: 0.6979 - val_loss: 0.7256\n",
      "Epoch 64/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.7883 - val_accuracy: 0.7083 - val_loss: 0.7120\n",
      "Epoch 65/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 585ms/step - accuracy: 0.7010 - loss: 0.7405 - val_accuracy: 0.6979 - val_loss: 0.8151\n",
      "Epoch 66/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.6291 - val_accuracy: 0.6458 - val_loss: 0.8412\n",
      "Epoch 67/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 680ms/step - accuracy: 0.7439 - loss: 0.6662 - val_accuracy: 0.6667 - val_loss: 0.9272\n",
      "Epoch 68/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7812 - loss: 0.5738 - val_accuracy: 0.6667 - val_loss: 0.8841\n",
      "Epoch 69/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 551ms/step - accuracy: 0.7577 - loss: 0.6645 - val_accuracy: 0.7396 - val_loss: 0.6903\n",
      "Epoch 70/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.6347 - val_accuracy: 0.7396 - val_loss: 0.7066\n",
      "Epoch 71/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 586ms/step - accuracy: 0.7298 - loss: 0.6940 - val_accuracy: 0.6354 - val_loss: 0.9253\n",
      "Epoch 72/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8438 - loss: 0.6286 - val_accuracy: 0.6146 - val_loss: 0.9578\n",
      "Epoch 73/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 559ms/step - accuracy: 0.7421 - loss: 0.6824 - val_accuracy: 0.6979 - val_loss: 0.7620\n",
      "Epoch 74/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6875 - loss: 0.7720 - val_accuracy: 0.6979 - val_loss: 0.7413\n",
      "Epoch 75/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.7530 - loss: 0.6398 - val_accuracy: 0.6562 - val_loss: 0.8877\n",
      "Epoch 76/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7188 - loss: 0.5753 - val_accuracy: 0.6875 - val_loss: 0.8448\n",
      "Epoch 77/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 559ms/step - accuracy: 0.7408 - loss: 0.6633 - val_accuracy: 0.6875 - val_loss: 0.8947\n",
      "Epoch 78/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.4862 - val_accuracy: 0.7396 - val_loss: 0.7907\n",
      "Epoch 79/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 582ms/step - accuracy: 0.7523 - loss: 0.6275 - val_accuracy: 0.7292 - val_loss: 0.6795\n",
      "Epoch 80/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8125 - loss: 0.4925 - val_accuracy: 0.6979 - val_loss: 0.7146\n",
      "Epoch 81/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 706ms/step - accuracy: 0.7274 - loss: 0.6946 - val_accuracy: 0.6979 - val_loss: 0.9266\n",
      "Epoch 82/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.5499 - val_accuracy: 0.7188 - val_loss: 0.8845\n",
      "Epoch 83/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 625ms/step - accuracy: 0.7445 - loss: 0.6375 - val_accuracy: 0.6250 - val_loss: 1.0032\n",
      "Epoch 84/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.8618 - val_accuracy: 0.6458 - val_loss: 1.0102\n",
      "Epoch 85/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 526ms/step - accuracy: 0.7496 - loss: 0.7022 - val_accuracy: 0.6875 - val_loss: 0.7737\n",
      "Epoch 86/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.7976 - val_accuracy: 0.6771 - val_loss: 0.8133\n",
      "Epoch 87/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 490ms/step - accuracy: 0.7391 - loss: 0.6647 - val_accuracy: 0.7292 - val_loss: 0.7021\n",
      "Epoch 88/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7188 - loss: 0.6696 - val_accuracy: 0.7500 - val_loss: 0.6853\n",
      "Epoch 89/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 491ms/step - accuracy: 0.7660 - loss: 0.6205 - val_accuracy: 0.7292 - val_loss: 0.8667\n",
      "Epoch 90/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6875 - loss: 0.7347 - val_accuracy: 0.7292 - val_loss: 0.8433\n",
      "Epoch 91/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 497ms/step - accuracy: 0.7480 - loss: 0.6402 - val_accuracy: 0.7500 - val_loss: 0.7730\n",
      "Epoch 92/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7500 - loss: 0.6782 - val_accuracy: 0.7396 - val_loss: 0.7625\n",
      "Epoch 93/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 506ms/step - accuracy: 0.7400 - loss: 0.6199 - val_accuracy: 0.7188 - val_loss: 0.7750\n",
      "Epoch 94/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8438 - loss: 0.4775 - val_accuracy: 0.6875 - val_loss: 0.8351\n",
      "Epoch 95/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 486ms/step - accuracy: 0.7592 - loss: 0.6492 - val_accuracy: 0.7500 - val_loss: 0.6330\n",
      "Epoch 96/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8438 - loss: 0.4318 - val_accuracy: 0.7396 - val_loss: 0.6216\n",
      "Epoch 97/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 487ms/step - accuracy: 0.7618 - loss: 0.6193 - val_accuracy: 0.6979 - val_loss: 0.7362\n",
      "Epoch 98/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.5473 - val_accuracy: 0.7292 - val_loss: 0.7400\n",
      "Epoch 99/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 485ms/step - accuracy: 0.7563 - loss: 0.6173 - val_accuracy: 0.7396 - val_loss: 0.7293\n",
      "Epoch 100/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.6931 - val_accuracy: 0.7604 - val_loss: 0.6887\n",
      "Epoch 101/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 484ms/step - accuracy: 0.7824 - loss: 0.5972 - val_accuracy: 0.7083 - val_loss: 0.6172\n",
      "Epoch 102/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5312 - loss: 1.0218 - val_accuracy: 0.7188 - val_loss: 0.7278\n",
      "Epoch 103/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 481ms/step - accuracy: 0.7610 - loss: 0.5984 - val_accuracy: 0.7083 - val_loss: 0.7024\n",
      "Epoch 104/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7188 - loss: 0.9448 - val_accuracy: 0.6979 - val_loss: 0.7373\n",
      "Epoch 105/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 521ms/step - accuracy: 0.7745 - loss: 0.5915 - val_accuracy: 0.7500 - val_loss: 0.6950\n",
      "Epoch 106/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7812 - loss: 0.4842 - val_accuracy: 0.7396 - val_loss: 0.8120\n",
      "Epoch 107/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 491ms/step - accuracy: 0.7638 - loss: 0.6218 - val_accuracy: 0.7500 - val_loss: 0.6533\n",
      "Epoch 108/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.6212 - val_accuracy: 0.7708 - val_loss: 0.6203\n",
      "Epoch 109/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 495ms/step - accuracy: 0.7841 - loss: 0.5287 - val_accuracy: 0.7604 - val_loss: 0.7244\n",
      "Epoch 110/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8750 - loss: 0.4943 - val_accuracy: 0.7708 - val_loss: 0.6857\n",
      "Epoch 111/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 494ms/step - accuracy: 0.7627 - loss: 0.5882 - val_accuracy: 0.6979 - val_loss: 1.0324\n",
      "Epoch 112/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8438 - loss: 0.5392 - val_accuracy: 0.7292 - val_loss: 1.0395\n",
      "Epoch 113/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 480ms/step - accuracy: 0.7595 - loss: 0.6617 - val_accuracy: 0.6979 - val_loss: 0.8099\n",
      "Epoch 114/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5938 - loss: 0.7721 - val_accuracy: 0.7396 - val_loss: 0.7410\n",
      "Epoch 115/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 493ms/step - accuracy: 0.7822 - loss: 0.5523 - val_accuracy: 0.7292 - val_loss: 0.7908\n",
      "Epoch 116/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7188 - loss: 0.5990 - val_accuracy: 0.7188 - val_loss: 0.8258\n",
      "Epoch 117/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 487ms/step - accuracy: 0.7523 - loss: 0.5935 - val_accuracy: 0.7500 - val_loss: 0.6529\n",
      "Epoch 118/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.4423 - val_accuracy: 0.7083 - val_loss: 0.6944\n",
      "Epoch 119/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.7709 - loss: 0.5590 - val_accuracy: 0.6667 - val_loss: 0.7754\n",
      "Epoch 120/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.5270 - val_accuracy: 0.6875 - val_loss: 0.7266\n",
      "Epoch 121/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.7783 - loss: 0.5369 - val_accuracy: 0.6979 - val_loss: 0.6761\n",
      "Epoch 122/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7500 - loss: 0.7444 - val_accuracy: 0.7292 - val_loss: 0.6664\n",
      "Epoch 123/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 485ms/step - accuracy: 0.7584 - loss: 0.5976 - val_accuracy: 0.7188 - val_loss: 0.8013\n",
      "Epoch 124/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7188 - loss: 0.7287 - val_accuracy: 0.7396 - val_loss: 0.7557\n",
      "Epoch 125/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 495ms/step - accuracy: 0.7916 - loss: 0.5643 - val_accuracy: 0.7708 - val_loss: 0.6610\n",
      "Epoch 126/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.3941 - val_accuracy: 0.8021 - val_loss: 0.6314\n",
      "Epoch 127/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.7967 - loss: 0.5288 - val_accuracy: 0.7083 - val_loss: 0.7117\n",
      "Epoch 128/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5312 - loss: 0.9604 - val_accuracy: 0.7188 - val_loss: 0.7016\n",
      "Epoch 129/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 486ms/step - accuracy: 0.7885 - loss: 0.5850 - val_accuracy: 0.6875 - val_loss: 0.7375\n",
      "Epoch 130/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.3477 - val_accuracy: 0.6875 - val_loss: 0.7041\n",
      "Epoch 131/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 492ms/step - accuracy: 0.7927 - loss: 0.5512 - val_accuracy: 0.6979 - val_loss: 0.7118\n",
      "Epoch 132/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.7465 - val_accuracy: 0.7083 - val_loss: 0.7077\n",
      "Epoch 133/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 479ms/step - accuracy: 0.7823 - loss: 0.5462 - val_accuracy: 0.6771 - val_loss: 0.9705\n",
      "Epoch 134/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7500 - loss: 0.5862 - val_accuracy: 0.6979 - val_loss: 0.9094\n",
      "Epoch 135/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 484ms/step - accuracy: 0.7827 - loss: 0.5795 - val_accuracy: 0.7812 - val_loss: 0.6113\n",
      "Epoch 136/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8438 - loss: 0.4622 - val_accuracy: 0.7812 - val_loss: 0.6112\n",
      "Epoch 137/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 556ms/step - accuracy: 0.7752 - loss: 0.5929 - val_accuracy: 0.7083 - val_loss: 0.7713\n",
      "Epoch 138/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9062 - loss: 0.3241 - val_accuracy: 0.7292 - val_loss: 0.7315\n",
      "Epoch 139/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 13s/step - accuracy: 0.7693 - loss: 0.5993 - val_accuracy: 0.7396 - val_loss: 0.7576\n",
      "Epoch 140/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8125 - loss: 0.5730 - val_accuracy: 0.7292 - val_loss: 0.7563\n",
      "Epoch 141/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 375ms/step - accuracy: 0.7891 - loss: 0.5360 - val_accuracy: 0.7292 - val_loss: 0.7068\n",
      "Epoch 142/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7449 - val_accuracy: 0.7500 - val_loss: 0.6624\n",
      "Epoch 143/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 352ms/step - accuracy: 0.8069 - loss: 0.5545 - val_accuracy: 0.7396 - val_loss: 0.7145\n",
      "Epoch 144/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.6791 - val_accuracy: 0.7500 - val_loss: 0.6782\n",
      "Epoch 145/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 393ms/step - accuracy: 0.8224 - loss: 0.5024 - val_accuracy: 0.7604 - val_loss: 0.6271\n",
      "Epoch 146/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7500 - loss: 0.5041 - val_accuracy: 0.7812 - val_loss: 0.6032\n",
      "Epoch 147/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 412ms/step - accuracy: 0.7723 - loss: 0.5562 - val_accuracy: 0.7188 - val_loss: 0.7516\n",
      "Epoch 148/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6875 - loss: 0.7611 - val_accuracy: 0.7083 - val_loss: 0.7778\n",
      "Epoch 149/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 417ms/step - accuracy: 0.7623 - loss: 0.5953 - val_accuracy: 0.7812 - val_loss: 0.7484\n",
      "Epoch 150/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.4779 - val_accuracy: 0.7812 - val_loss: 0.7678\n",
      "Epoch 151/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 433ms/step - accuracy: 0.7971 - loss: 0.5261 - val_accuracy: 0.7292 - val_loss: 0.7122\n",
      "Epoch 152/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.5177 - val_accuracy: 0.7292 - val_loss: 0.7612\n",
      "Epoch 153/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 452ms/step - accuracy: 0.8170 - loss: 0.5014 - val_accuracy: 0.7812 - val_loss: 0.6850\n",
      "Epoch 154/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.5313 - val_accuracy: 0.7812 - val_loss: 0.7120\n",
      "Epoch 155/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.7884 - loss: 0.5176 - val_accuracy: 0.7604 - val_loss: 0.7603\n",
      "Epoch 156/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9062 - loss: 0.3104 - val_accuracy: 0.7396 - val_loss: 0.8273\n",
      "Epoch 157/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 472ms/step - accuracy: 0.7943 - loss: 0.5311 - val_accuracy: 0.7604 - val_loss: 0.6883\n",
      "Epoch 158/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7188 - loss: 0.6064 - val_accuracy: 0.7292 - val_loss: 0.6917\n",
      "Epoch 159/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.8243 - loss: 0.4991 - val_accuracy: 0.7292 - val_loss: 0.8986\n",
      "Epoch 160/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.7170 - val_accuracy: 0.7292 - val_loss: 0.8640\n",
      "Epoch 161/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 491ms/step - accuracy: 0.8027 - loss: 0.5426 - val_accuracy: 0.7292 - val_loss: 0.7802\n",
      "Epoch 162/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.5035 - val_accuracy: 0.7396 - val_loss: 0.7427\n",
      "Epoch 163/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 482ms/step - accuracy: 0.8108 - loss: 0.4882 - val_accuracy: 0.7604 - val_loss: 0.8982\n",
      "Epoch 164/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7778 - loss: 0.5017 - val_accuracy: 0.7500 - val_loss: 0.8833\n",
      "Epoch 165/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 487ms/step - accuracy: 0.8042 - loss: 0.5303 - val_accuracy: 0.7188 - val_loss: 0.8703\n",
      "Epoch 166/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9375 - loss: 0.4394 - val_accuracy: 0.7083 - val_loss: 0.8177\n",
      "Epoch 167/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 492ms/step - accuracy: 0.8158 - loss: 0.5450 - val_accuracy: 0.7396 - val_loss: 0.8635\n",
      "Epoch 168/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6875 - loss: 1.0709 - val_accuracy: 0.7083 - val_loss: 0.8361\n",
      "Epoch 169/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 479ms/step - accuracy: 0.7817 - loss: 0.5179 - val_accuracy: 0.7292 - val_loss: 0.7107\n",
      "Epoch 170/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.5336 - val_accuracy: 0.7396 - val_loss: 0.7100\n",
      "Epoch 171/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 482ms/step - accuracy: 0.8164 - loss: 0.5232 - val_accuracy: 0.7188 - val_loss: 0.7059\n",
      "Epoch 172/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7188 - loss: 0.5567 - val_accuracy: 0.7188 - val_loss: 0.7101\n",
      "Epoch 173/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 558ms/step - accuracy: 0.8145 - loss: 0.4537 - val_accuracy: 0.7500 - val_loss: 0.6187\n",
      "Epoch 174/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.6973 - val_accuracy: 0.7396 - val_loss: 0.6629\n",
      "Epoch 175/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 20s/step - accuracy: 0.7899 - loss: 0.5437 - val_accuracy: 0.7396 - val_loss: 0.6456\n",
      "Epoch 176/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8438 - loss: 0.4869 - val_accuracy: 0.7604 - val_loss: 0.6361\n",
      "Epoch 177/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 451ms/step - accuracy: 0.8000 - loss: 0.4881 - val_accuracy: 0.7188 - val_loss: 0.7783\n",
      "Epoch 178/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.4173 - val_accuracy: 0.7396 - val_loss: 0.7651\n",
      "Epoch 179/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 366ms/step - accuracy: 0.8134 - loss: 0.4843 - val_accuracy: 0.7708 - val_loss: 0.7010\n",
      "Epoch 180/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9062 - loss: 0.3616 - val_accuracy: 0.7604 - val_loss: 0.7307\n",
      "Epoch 181/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 405ms/step - accuracy: 0.8114 - loss: 0.4957 - val_accuracy: 0.7604 - val_loss: 0.8402\n",
      "Epoch 182/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8438 - loss: 0.4460 - val_accuracy: 0.7604 - val_loss: 0.8374\n",
      "Epoch 183/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 416ms/step - accuracy: 0.8185 - loss: 0.5088 - val_accuracy: 0.7604 - val_loss: 0.6658\n",
      "Epoch 184/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.4871 - val_accuracy: 0.7292 - val_loss: 0.6781\n",
      "Epoch 185/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 423ms/step - accuracy: 0.8188 - loss: 0.4836 - val_accuracy: 0.7292 - val_loss: 0.6662\n",
      "Epoch 186/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7188 - loss: 0.6198 - val_accuracy: 0.7083 - val_loss: 0.6741\n",
      "Epoch 187/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 431ms/step - accuracy: 0.8079 - loss: 0.4969 - val_accuracy: 0.7292 - val_loss: 0.6804\n",
      "Epoch 188/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8750 - loss: 0.3178 - val_accuracy: 0.7396 - val_loss: 0.6078\n",
      "Epoch 189/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 440ms/step - accuracy: 0.7938 - loss: 0.5343 - val_accuracy: 0.7188 - val_loss: 0.6645\n",
      "Epoch 190/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8750 - loss: 0.4785 - val_accuracy: 0.7083 - val_loss: 0.6524\n",
      "Epoch 191/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 453ms/step - accuracy: 0.8182 - loss: 0.4482 - val_accuracy: 0.7083 - val_loss: 0.7241\n",
      "Epoch 192/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.5645 - val_accuracy: 0.7083 - val_loss: 0.7299\n",
      "Epoch 193/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 465ms/step - accuracy: 0.8086 - loss: 0.4527 - val_accuracy: 0.7604 - val_loss: 0.6910\n",
      "Epoch 194/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.4786 - val_accuracy: 0.7708 - val_loss: 0.6606\n",
      "Epoch 195/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 473ms/step - accuracy: 0.8270 - loss: 0.4272 - val_accuracy: 0.6979 - val_loss: 0.8189\n",
      "Epoch 196/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.5211 - val_accuracy: 0.6979 - val_loss: 0.7943\n",
      "Epoch 197/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 478ms/step - accuracy: 0.8028 - loss: 0.5030 - val_accuracy: 0.7188 - val_loss: 0.6491\n",
      "Epoch 198/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8438 - loss: 0.5237 - val_accuracy: 0.7188 - val_loss: 0.6713\n",
      "Epoch 199/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 474ms/step - accuracy: 0.8249 - loss: 0.4710 - val_accuracy: 0.7292 - val_loss: 0.5891\n",
      "Epoch 200/200\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.4267 - val_accuracy: 0.7396 - val_loss: 0.5641\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=200,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7086 - loss: 0.6001 \n",
      "Test accuracy: 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "The snake species is: Bungarus multicinctus\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict_snake(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize the image\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    class_label = list(train_generator.class_indices.keys())[class_idx]\n",
    "    return class_label\n",
    "\n",
    "# Example usage\n",
    "result = predict_snake(r'data/test/Bungarus multicinctus/7ddedcd0504341d7a7820d0480631191.jpg')\n",
    "print(f'The snake species is: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/snakeimageclassifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and class names saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save class names as a JSON array\n",
    "snake_names = list(train_generator.class_indices.keys())  # Extract class names as an array\n",
    "with open(\"models/snake_class_names.json\", \"w\") as f:\n",
    "    json.dump(snake_names, f)\n",
    "\n",
    "print(\"Model and class names saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
